{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"AxMn4-v_hV2x"},"source":["About the Dataset:\n","\n","id: unique id for a news article\n","\n","title: the title of a news article\n","\n","author: author of the news article\n","\n","text: the text of the article; could be incomplete\n","\n","label: a label that marks whether the news article is real or fake: 1: Fake news 0: real News"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":479,"status":"ok","timestamp":1684588785712,"user":{"displayName":"Group Project","userId":"07783678051926076974"},"user_tz":-330},"id":"DF0xf18Rctj6"},"outputs":[],"source":["import numpy as np                                                              #numpy array\n","import pandas as pd                                                             #use to create dataframe\n","import re                                                                       #regularExpression\n","import nltk\n","import pickle\n","from nltk.corpus import stopwords                                               #stopwords are words which have less value ex is,the\n","from nltk.stem.porter import PorterStemmer                                      #for stemming purpose\n","from sklearn.feature_extraction.text import TfidfVectorizer                     #convert text to features\n","from sklearn.model_selection import train_test_split                            #help in splitting training data and test data\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1399,"status":"ok","timestamp":1684588959615,"user":{"displayName":"Group Project","userId":"07783678051926076974"},"user_tz":-330},"id":"OKVXcXZoV8id"},"outputs":[],"source":["# load the dataset\n","df = pd.read_csv('./train.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1684588963604,"user":{"displayName":"Group Project","userId":"07783678051926076974"},"user_tz":-330},"id":"66VMTLX0c4X7"},"outputs":[],"source":["# counting the number of missing values in the dataset\n","df.isnull().sum()\n","\n","# replacing the null values with empty string\n","df = df.fillna('')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1684588966271,"user":{"displayName":"Group Project","userId":"07783678051926076974"},"user_tz":-330},"id":"Lo76UuK0cSPS","outputId":"35dabf49-e78a-41c8-ea82-f2972b16b481"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\Aniket\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('stopwords')                                                      #downloading stopwords"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":412,"status":"ok","timestamp":1684588989614,"user":{"displayName":"Group Project","userId":"07783678051926076974"},"user_tz":-330},"id":"yiKTwAhCUJQf"},"outputs":[],"source":["port_stem = PorterStemmer()                       #Loading porterStemmer() function to this variable port_stem\n","\n","def stemming(content):\n","    stemmed_content = re.sub('[^a-zA-Z]',' ',content)       #removing numbers and punctuations from content & replace it with empty string\n","    stemmed_content = stemmed_content.lower()               #coverting everything to lower case\n","    stemmed_content = stemmed_content.split()               #creating a list [\"the\", \"is\",....] like this\n","    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] #removing stopwords then performing stemming\n","    stemmed_content = ' '.join(stemmed_content)             #joining the list ex. the is\n","    return stemmed_content"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":55918,"status":"ok","timestamp":1684589047967,"user":{"displayName":"Group Project","userId":"07783678051926076974"},"user_tz":-330},"id":"nQKLKrj9WBTG"},"outputs":[],"source":["# preprocess the data by applying stemming to the title and author columns\n","df['title'] = df['title'].apply(stemming)\n","df['author'] = df['author'].apply(stemming)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":406,"status":"ok","timestamp":1684589051497,"user":{"displayName":"Group Project","userId":"07783678051926076974"},"user_tz":-330},"id":"Np58i56DWE_t"},"outputs":[],"source":["# combine the title and author columns into a single text column\n","df['text'] = df['title'] + ' ' + df['author']"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":724,"status":"ok","timestamp":1684589054025,"user":{"displayName":"Group Project","userId":"07783678051926076974"},"user_tz":-330},"id":"AXeyWVZaWHqd"},"outputs":[],"source":["# vectorize the text using TF-IDF\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(df['text'])\n","y = df['label']"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1684589056097,"user":{"displayName":"Group Project","userId":"07783678051926076974"},"user_tz":-330},"id":"mcBUxnG2WLje"},"outputs":[],"source":["# split the data into training and testing sets\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":529,"status":"ok","timestamp":1684589058539,"user":{"displayName":"Group Project","userId":"07783678051926076974"},"user_tz":-330},"id":"Q5-Bs-daWOad","outputId":"754e2ff8-8b2d-4dfc-b547-991f54095bc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9740384615384615\n"]}],"source":["# fit a logistic regression model to the training data\n","model = LogisticRegression()\n","model.fit(x_train, y_train)\n","\n","# evaluate the model on the testing data\n","y_pred = model.predict(x_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print('Accuracy:', accuracy)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["with open('vectorizer.pkl', 'wb') as file:\n","        pickle.dump(vectorizer, file)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1684589060650,"user":{"displayName":"Group Project","userId":"07783678051926076974"},"user_tz":-330},"id":"XQcToWYFWSoF","outputId":"5650d12c-2c0c-4cd4-e204-0ee7e51a292a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model saved\n"]}],"source":["# save the model using pickle\n","#filename = 'logisticRegressionSavedModelTitleAuthor.pkl'\n","#with open(filename, 'wb') as file:\n","#    pickle.dump(model, file)\n","\n","# load the model and make predictions on new data\n","#with open(filename, 'rb') as file:\n","#    loaded_model = pickle.load(file)\n","#new_text = 'Specter of Trump Loosens Tongues, if Not Purse Strings, in Silicon Valley - The New York Times'\n","#new_text = stemming(new_text)\n","#new_text = vectorizer.transform([new_text])\n","#prediction = loaded_model.predict(new_text)[0]\n","#if prediction == 1:\n","#    print('Fake news')\n","#else:\n","#    print('Real news')\n","\n","\n","filename = 'logisticRegressionSavedModelTitleAuthor.pkl'\n","pickle.dump(model, open(filename, 'wb'))\n","print(\"Model saved\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOy9jI4s64J1IHsmUw2GHlJ","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"vscode":{"interpreter":{"hash":"26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"}}},"nbformat":4,"nbformat_minor":0}
