{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"AxMn4-v_hV2x"},"source":["About the Dataset:\n","\n","id: unique id for a news article\n","\n","title: the title of a news article\n","\n","author: author of the news article\n","\n","text: the text of the article; could be incomplete\n","\n","label: a label that marks whether the news article is real or fake: 1: Fake news 0: real News"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"DF0xf18Rctj6"},"outputs":[],"source":["import numpy as np                                                              #numpy array\n","import pandas as pd                                                             #use to create dataframe\n","import re                                                                       #regularExpression\n","import nltk\n","import pickle\n","from nltk.corpus import stopwords                                               #stopwords are words which have less value ex is,the\n","from nltk.stem.porter import PorterStemmer                                      #for stemming purpose\n","from sklearn.feature_extraction.text import TfidfVectorizer                     #convert text to features\n","from sklearn.model_selection import train_test_split                            #help in splitting training data and test data\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import cross_val_score"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"OKVXcXZoV8id"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/train.csv'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# load the dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m/content/train.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train.csv'"]}],"source":["# load the dataset\n","df = pd.read_csv('./train.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"66VMTLX0c4X7"},"outputs":[],"source":["# counting the number of missing values in the dataset\n","df.isnull().sum()\n","\n","# replacing the null values with empty string\n","df = df.fillna('')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1684588966271,"user":{"displayName":"Group Project","userId":"07783678051926076974"},"user_tz":-330},"id":"Lo76UuK0cSPS","outputId":"35dabf49-e78a-41c8-ea82-f2972b16b481"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('stopwords')                                                      #downloading stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiKTwAhCUJQf"},"outputs":[],"source":["port_stem = PorterStemmer()                       #Loading porterStemmer() function to this variable port_stem\n","\n","def stemming(content):\n","    stemmed_content = re.sub('[^a-zA-Z]',' ',content)       #removing numbers and punctuations from content & replace it with empty string\n","    stemmed_content = stemmed_content.lower()               #coverting everything to lower case\n","    stemmed_content = stemmed_content.split()               #creating a list [\"the\", \"is\",....] like this\n","    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] #removing stopwords then performing stemming\n","    stemmed_content = ' '.join(stemmed_content)             #joining the list ex. the is\n","    return stemmed_content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQKLKrj9WBTG"},"outputs":[],"source":["# preprocess the data by applying stemming to the title and author columns\n","df['title'] = df['title'].apply(stemming)\n","df['author'] = df['author'].apply(stemming)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Np58i56DWE_t"},"outputs":[],"source":["# combine the title and author columns into a single text column\n","df['text'] = df['title'] + ' ' + df['author']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AXeyWVZaWHqd"},"outputs":[],"source":["# vectorize the text using TF-IDF\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(df['text'])\n","y = df['label']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mcBUxnG2WLje"},"outputs":[],"source":["# split the data into training and testing sets\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":529,"status":"ok","timestamp":1684589058539,"user":{"displayName":"Group Project","userId":"07783678051926076974"},"user_tz":-330},"id":"Q5-Bs-daWOad","outputId":"754e2ff8-8b2d-4dfc-b547-991f54095bc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9740384615384615\n"]}],"source":["# fit a logistic regression model to the training data\n","model = LogisticRegression()\n","model.fit(x_train, y_train)\n","\n","# evaluate the model on the testing data\n","y_pred = model.predict(x_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print('Accuracy:', accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Perform k-fold cross-validation\n","k = 5  # Number of folds\n","scores = cross_val_score(model, X, y, cv=k, scoring='accuracy')\n","\n","print(\"Cross-Validation Scores:\", scores)\n","print(\"Mean Accuracy:\", scores.mean())\n","\n","model.fit(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1684589060650,"user":{"displayName":"Group Project","userId":"07783678051926076974"},"user_tz":-330},"id":"XQcToWYFWSoF","outputId":"5650d12c-2c0c-4cd4-e204-0ee7e51a292a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Real news\n"]}],"source":["# save the model using pickle\n","filename = 'logisticRegressionSavedModelTitleAuthor.pkl'\n","with open(filename, 'wb') as file:\n","    pickle.dump(model, file)\n","\n","# load the model and make predictions on new data\n","with open(filename, 'rb') as file:\n","    loaded_model = pickle.load(file)\n","new_text = 'Specter of Trump Loosens Tongues, if Not Purse Strings, in Silicon Valley - The New York Times'\n","new_text = stemming(new_text)\n","new_text = vectorizer.transform([new_text])\n","prediction = loaded_model.predict(new_text)[0]\n","if prediction == 1:\n","    print('Fake news')\n","else:\n","    print('Real news')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNOSIeoiOQPvssRFRUBofkL","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
