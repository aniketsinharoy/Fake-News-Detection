{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNOSIeoiOQPvssRFRUBofkL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["About the Dataset:\n","\n","id: unique id for a news article\n","\n","title: the title of a news article\n","\n","author: author of the news article\n","\n","text: the text of the article; could be incomplete\n","\n","label: a label that marks whether the news article is real or fake: 1: Fake news 0: real News"],"metadata":{"id":"AxMn4-v_hV2x"}},{"cell_type":"code","source":["import numpy as np                                                              #numpy array\n","import pandas as pd                                                             #use to create dataframe\n","import re                                                                       #regularExpression\n","import nltk\n","import pickle\n","from nltk.corpus import stopwords                                               #stopwords are words which have less value ex is,the\n","from nltk.stem.porter import PorterStemmer                                      #for stemming purpose\n","from sklearn.feature_extraction.text import TfidfVectorizer                     #convert text to features\n","from sklearn.model_selection import train_test_split                            #help in splitting training data and test data\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"DF0xf18Rctj6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load the dataset\n","df = pd.read_csv('/content/train.csv')"],"metadata":{"id":"OKVXcXZoV8id"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# counting the number of missing values in the dataset\n","df.isnull().sum()\n","\n","# replacing the null values with empty string\n","df = df.fillna('')"],"metadata":{"id":"66VMTLX0c4X7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')                                                      #downloading stopwords"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lo76UuK0cSPS","executionInfo":{"status":"ok","timestamp":1684588966271,"user_tz":-330,"elapsed":7,"user":{"displayName":"Group Project","userId":"07783678051926076974"}},"outputId":"35dabf49-e78a-41c8-ea82-f2972b16b481"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["port_stem = PorterStemmer()                       #Loading porterStemmer() function to this variable port_stem\n","\n","def stemming(content):\n","    stemmed_content = re.sub('[^a-zA-Z]',' ',content)       #removing numbers and punctuations from content & replace it with empty string\n","    stemmed_content = stemmed_content.lower()               #coverting everything to lower case\n","    stemmed_content = stemmed_content.split()               #creating a list [\"the\", \"is\",....] like this\n","    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] #removing stopwords then performing stemming\n","    stemmed_content = ' '.join(stemmed_content)             #joining the list ex. the is\n","    return stemmed_content"],"metadata":{"id":"yiKTwAhCUJQf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preprocess the data by applying stemming to the title and author columns\n","df['title'] = df['title'].apply(stemming)\n","df['author'] = df['author'].apply(stemming)"],"metadata":{"id":"nQKLKrj9WBTG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# combine the title and author columns into a single text column\n","df['text'] = df['title'] + ' ' + df['author']"],"metadata":{"id":"Np58i56DWE_t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# vectorize the text using TF-IDF\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(df['text'])\n","y = df['label']"],"metadata":{"id":"AXeyWVZaWHqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# split the data into training and testing sets\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"mcBUxnG2WLje"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fit a logistic regression model to the training data\n","model = LogisticRegression()\n","model.fit(x_train, y_train)\n","\n","# evaluate the model on the testing data\n","y_pred = model.predict(x_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print('Accuracy:', accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5-Bs-daWOad","executionInfo":{"status":"ok","timestamp":1684589058539,"user_tz":-330,"elapsed":529,"user":{"displayName":"Group Project","userId":"07783678051926076974"}},"outputId":"754e2ff8-8b2d-4dfc-b547-991f54095bc2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9740384615384615\n"]}]},{"cell_type":"code","source":["# save the model using pickle\n","filename = 'logisticRegressionSavedModelTitleAuthor.pkl'\n","with open(filename, 'wb') as file:\n","    pickle.dump(model, file)\n","\n","# load the model and make predictions on new data\n","with open(filename, 'rb') as file:\n","    loaded_model = pickle.load(file)\n","new_text = 'Specter of Trump Loosens Tongues, if Not Purse Strings, in Silicon Valley - The New York Times'\n","new_text = stemming(new_text)\n","new_text = vectorizer.transform([new_text])\n","prediction = loaded_model.predict(new_text)[0]\n","if prediction == 1:\n","    print('Fake news')\n","else:\n","    print('Real news')"],"metadata":{"id":"XQcToWYFWSoF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684589060650,"user_tz":-330,"elapsed":6,"user":{"displayName":"Group Project","userId":"07783678051926076974"}},"outputId":"5650d12c-2c0c-4cd4-e204-0ee7e51a292a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Real news\n"]}]},{"cell_type":"code","source":["#flask code for deployment\n","from flask import Flask, render_template, request\n","import pickle\n","import numpy as np\n","\n","\n","app=Flask(__name__)\n","\n","\n","@app.route('/')\n","def index_view():\n","    return render_template(\"index.html\")\n"," \n","@app.route('/predict', methods = ['GET','POST'])\n","def predict():\n","    if request.method == 'POST':\n","        with open(\"logisticRegressionSavedModelTitleAuthor.pkl\", \"rb\") as file:\n","            loaded_model=pickle.load(file)\n","\n","        t=request.form.get('title')\n","        a=request.form.get('author')\n","\n","        text=t+' '+a\n","        #return text\n","        new_text=np.array(text)\n","        predict = loaded_model.predict(new_text)\n","      \n","        if int(predict)== 0:\n","            return render_template(\"real.html\", prediction=predict)\n","        else:\n","            return render_template(\"fake.html\", prediction=predict)\n","\n","if __name__==\"__main__\":\n","    app.run()"],"metadata":{"id":"9D-1G7yRlXNn"},"execution_count":null,"outputs":[]}]}